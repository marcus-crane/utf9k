







































































































[{"content":"No! As I learned recently, only a handful of regions feature multiple availability zones.\n\nHaving originally started out using [AWS](https://aws.amazon.com), I had assumed that every region has multiple availability zones.\n\nAzure maintains [a list](https://docs.microsoft.com/en-us/azure/availability-zones/az-region#azure-regions-with-availability-zones) of regions with multiple AZs so if you need redundancy, you're best off picking one of these.\n\nSome services may refuse to deploy entirely (such as \"geo-redundant\" gateways in us-east as I found out recently)\n","slug":"azure-regions-alike","tags":["availability","azure","cloud","microsoft"],"title":"Are all Azure regions alike?"},{"content":"I've known about this tool for some time now but I'm writing about it because I ALWAYS forget to use it.\n\n`pbcopy`, and as I just discovered, `pbpaste` are two tools that are built into macOS.\n\nYou can pipe data into the former to add it to your clipboard and similarly, you can use the latter as input into a unix pipeline.\n\nLet's look at an example:\n\n```bash\n> echo \"see you on the other side\" | pbcopy\n```\n\nYou can now use `Ctrl+V` to paste this text into any GUI application. Saves you having to mouse over to the terminal and highlight text but I still do it every darn time.\n\nWe can also use our clipboard contents too as mentioned. You could have copied some text from a GUI application and you want to use it in your terminal.\n\n```bash\n# Clipboard contains \"utf9k.net\" that I copied from my browser\n> pbpaste | xargs dig TXT | grep \"I see\"\nutf9k.net.    3444  IN  TXT \"I see you snoopin' around ;) If you're after something, you can feel fr\\010ee to email me at marcus@utf9k.net\"\n```\n\nWhat I'm trying to say is that I have all of the tools at my disposal to avoid [RSI](https://en.wikipedia.org/wiki/Repetitive_strain_injury) but I just need to remember they exist...","slug":"macos-clipboard-piping","tags":["clipboard","macos","terminal"],"title":"How can I access my clipboard contents inside my terminal?"},{"content":"The following should roughly do it. Your mileage may vary!\n\n```shell\ngit clone -b emacs-27 git://git.sv.gnu.org/emacs.git\ncd emacs\nsudo apt-get build-dep emacs\n./autogen.sh\n./configure --with-x-toolkit=lucid --with-mailutils\nmake -j4\n./src/emacs // test that its working\nsudo make install\n```","slug":"emacs-compile-from-source","tags":["emacs"],"title":"How can I compile Emacs from source?"},{"content":"Recently, a coworker of mine got a new laptop and needed to connect to the printer at work. One of the dialog boxes asked for the \"print queue\".\n\nFor the unfamiliar, here's what the macOS printer settings look like.\n\n![A screenshot of the macOS System Preferences pane for printing. It shows one registered printer on the left called example-printer which is sitting idle. It has the type Generic PostScript Printer. Nothing here indicates the queue name.](https://cdn.utf9k.net/questions/macos-printer-cli/printer-overview.png)\n\nI can't see any queue settings so let's dive a little deeper.\n\n![A screenshot of the macOS System Preferences pane. It has the settings window open for the printer from earlier called example-printer. There are only a few piece of information such as device name and driver version which are not helpful at all. There is only a single interactive checkbox with the label Use Generic Printer Features with no description of what that means. There is still nothing to indicate the queue name we are looking for.](https://cdn.utf9k.net/questions/macos-printer-cli/printer-settings.png)\n\nNothing here either but surely there must be something under the hood. Thankfully, there's a built in command called `lpstat` that allows all sorts of printer configuration.\n\n```bash\n> man lpstat | grep lpstat\nlpstat(1)                          Apple Inc.                          lpstat(1)\n       lpstat - print cups status information\n26 April 2019                         CUPS                             lpstat(1)\n```\n\nIn order to find the printer queue name, I was able to make use of `lpstat -s` like so:\n\n```bash\n> lpstat -s\nsystem default destination: example_printer\ndevice for example_printer: ipp://example-printer/my-fake-queue\n```\n\nAh, so the queue name is `my-fake-queue`. I wish the System Preferences pane had just said so earlier.\n\nWhile there, I also discovered a bunch of my old print jobs as well!\n\n```bash\n> lpstat -W completed -l\nexample_printer-3 marcus          59392   Wed 28 Apr 09:40:30 2021\n    Status: The printer is not responding.\n    Alerts: processing-to-stop-point\n    queued for example_printer\nexample_printer-2 marcus         113664   Wed 17 Mar 15:36:56 2021\n    Status: The printer is unreachable at this time.\n    Alerts: job-canceled-by-user\n    queued for example_printer\nexample_printer-1 marcus          51200   Thu  8 Oct 11:14:01 2020\n    Status:\n    Alerts: processing-to-stop-point\n    queued for example_printer\n```\n\nHopefully this makes your printing life easier, or at least gives you some closure on why those months old jobs refused to print.","slug":"macos-printer-cli","tags":["macos","printers"],"title":"How can I configure my printer via terminal on macOS?"},{"content":"If you're trying to test out a job, and don't want to wait for however long, you can manually create a job instance.\n\nAssuming our cronjob is called `sports-leaderboard-calc`, you can create it like so:\n\n```bash\n> kubectl create job instance-name --from=cronjob/sports-leaderboard-calc\njob.batch/instance-name\n```\n\nYou'll then see the resulting job and pod under `kubectl get job` and `kubectl get pod` respectively.","slug":"kubes-create-cron-instance","tags":["cronjob","kubernetes"],"title":"How can I create an instance of a Kube cronjob?"},{"content":"I suppose they aren't used too much anymore but I've started using them as a preview window for my [projects](/projects) page.\n\nIt can be handy to act different depending on an iFrame, such as scaling the view port.\n\nYou **can't** do something like this:\n\n```css\niframe > canvas {\n  width: 500px;\n}\n\ncanvas {\n  width: 100%;\n}\n```\n\nbut you can use Javascript inside an iFrame and make the changes within the frame itself, rather than from the outside:\n\n```javascript\nfunction insideIframe() {\n  try {\n    return window.self !== window.top\n  } catch (e) {\n    return true\n  }\n}\n\nif (insideIframe()) {\n  // perhaps change the size of something or just act differently\n}\n```","slug":"js-detect-iframe-parent","tags":["iframe","javascript"],"title":"How can I determine if my code is inside of an iFrame?"},{"content":"This question [was trending](https://news.ycombinator.com/item?id=28361730) on [Hacker News](https://news.ycombinator.com) but the thread in question never addressed it.\n\nBuried down in the comments was a technical fix [suggested by torstenvl](https://news.ycombinator.com/item?id=28362014).\n\nSafari has a few configuration entries accessible via `defaults read com.apple.coreservices.uiagent`.\n\nWhile I haven't tested this personally, `torstenvl` recommended stubbing out the notification with the following commands:\n\n```shell\ndefaults write com.apple.coreservices.uiagent CSUIHasSafariBeenLaunched -bool YES\ndefaults write com.apple.coreservices.uiagent CSUIRecommendSafariNextNotificationDate -date 2050-01-01T00:00:00Z\ndefaults write com.apple.coreservices.uiagent CSUILastOSVersionWhereSafariRecommendationWasMade -float 99.99\n```\n\nIf this works for you, let me know. I'm currently running the macOS Monterey beta at the time of writing and as I've already used Safari, I don't believe I get this notification anymore.\n","slug":"macos-disable-safari-recommendation","tags":["macos","safari","software"],"title":"How can I disable the 'Try the new Safari' notification?"},{"content":"Using `pg_dump`, which ships with the `psql` executable, it's a pretty simple progress\n\n```bash\npg_dump --dbname={{DBNAME}} --host={{HOST}} --port={{PORT}} --username={{USERNAME}} --password --format=c > {{NAME}}.dump\n# The c in --format=c stands for custom\n```","slug":"postgres-export-db","tags":["databases","postgres"],"title":"How can I export a Postgres database?"},{"content":"This error is usually pretty cryptic and I often forget how to debug it so let's look at a sample error:\n\n```bash\nError: The module '/Users/marcus/Code/octowise/node_modules/better-sqlite3/build/Release/better_sqlite3.node'\nwas compiled against a different Node.js version using\nNODE_MODULE_VERSION 83. This version of Node.js requires\nNODE_MODULE_VERSION 89.\n```\n\nI often remember that I need to possibly use a different version of nodejs but I never remember how to tell which one.\n\nThe official NodeJS site has a table with version numbers and their corresponding `NODE_MODULE_VERSION` [available here](https://nodejs.org/en/download/releases/).\n\nIn the case of this error, I think I probably want to downgrade to `Node.js 14.x`? It's all very confusing.\n","slug":"nodejs-module-version","tags":["javascript","nodejs"],"title":"How can I find my current NODE_MODULE_VERSION?"},{"content":"## \n\nWhile there's the classic `Apple menu -> About This Mac -> System Report`, a terminal based alternative is the `system_profiler` command.\n\nYou can use a list of queryable types like so:\n\n```bash\n> system_profiler -listDataTypes\nAvailable Datatypes:\nSPParallelATADataType\nSPUniversalAccessDataType\n[...]\n```\n\nOnce you've found one or more types, you're interested in then just append it after the command like so: `system_profiler <type1> <type2>`\n\nLet's see how it looks in action:\n\n```bash\n> system_profiler SPPowerDataType\nPower:\n\n    Battery Information:\n\n      Model Information:\n          Manufacturer: DSY\n          Device Name: bq20z451\n          Pack Lot Code: 0\n          PCB Lot Code: 0\n          Firmware Version: 1002\n          Hardware Revision: 1\n          Cell Revision: 2400\n      Charge Information:\n          Fully Charged: No\n          Charging: Yes\n          Full Charge Capacity (mAh): 4569\n          State of Charge (%): 74\n      Health Information:\n          Cycle Count: 81\n          Condition: Normal\n```\n\nThis is just an excerpt of what is otherwise a whole bunch of information.\n\nParticularly interesting is the `SPAirPortDataType` which can be queried to see a list of SSIDs in the environment.","slug":"macos-view-hardware","tags":["hardware","macos"],"title":"How can I find out more about the hardware inside my Mac?"},{"content":"You can see a list of current `auth-sources` by running the following `elisp` function\n\n```lisp\n> auth-sources\n(password-store \"~/.authinfo.gpg\")\n```\n","slug":"emacs-auth-sources","tags":["elisp","emacs"],"title":"How can I find out where Emacs is checking for passwords?"},{"content":"This is arguably one of the more obscure commands I've come across. At the time, a coworker of mine was having issues where his laptop would restart seemingly at random.\n\nWe were able to find out a bit more with the following command:\n\n```bash\nlog show -predicate 'eventMessage contains \"Previous shutdown cause\"' -last 24h\n```\n\nIt may take a minute or so to actually find some logs but it should reveal a shutdown code.\n\nI don't remember where I dug it up but you can see a list of shutdown causes and their meanings [in this PDF](https://cdn.utf9k.net/questions/macos-check-shutdown-cause/shutdown-causes.pdf).\n\nHere's how the results looks on my machine where I had performed a normal shutdown as a test\n\n![An iTerm2 window showing the results of the command mentioned above. There is one result for a previous shutdown with the cause code of 5. This indicates a normal shutdown.](https://cdn.utf9k.net/questions/macos-check-shutdown-cause/normal-shutdown.png)\n\nIf we compare the shutdown code to the PDF above, we can see the description is `Correct shut down` which lines up exactly.\n\nNow let's take this information and use it to see what was potentially happening to my coworkers laptop.\n\nHere's a screenshot of his terminal window with the same command:\n\n![A macOS Terminal window showing the results of the previous command on a different machine. There are seven results for a cause code of -128. This indicates an abnormal shutdown.](https://cdn.utf9k.net/questions/macos-check-shutdown-cause/abnormal-shutdown.png)\n\nGoing back to the PDF again, we can see that `-128` is an alias for `-112`. Checking `-112` tells us that it is \"Probably memory related\" which at least narrows it down.\n\nI don't doubt that result since some of the most authoritative information can often be found in PDFs randomly floating around the internet!\n\nFor anyone wondering, my coworker has a new laptop on the way regardless, since he can't work with it constantly rebooting.\n","slug":"macos-check-shutdown-cause","tags":["crashes","logging","macos"],"title":"How can I find out why my Mac has restarted?"},{"content":"While you can delete stock folders such as `Templates`, `Public` and so on, they'll still appear in the sidebar of your file explorer.\n\nThe good news is that they're pretty easy to disable.\n\nReferring to the [xdg-user-dirs](https://freedesktop.org/wiki/Software/xdg-user-dirs/#settings) manual shows us that there is a configuration file of \"well known\" user directories that lives at `$HOME/.config/user-dirs.dirs` by default\n\nSimply deleting the various entries inside might break a number of things but if you look closely, you'll spot that changing a directory to point to your home directory will disable it\n\nFor example:\n\n```shell\n> cat $HOME/.config/user-dirs.dirs\nXDG_TEMPLATES_DIR=\"$HOME\" # templates is now disabled\n```\n\nThis should cause the Templates folder to disappear from the sidebar of Nautilus although you might need to restart first.\n","slug":"linux-disable-stock-folders","tags":["housekeeping","linux","xdg"],"title":"How can I get rid of the default application folders that ship with my Linux distro?"},{"content":"This has been something that has plagued me for years and I've never sat down to properly fix it.\n\nInstead, I've just added `.DS_Store` to `.gitignore` files probably over one hundred times by over.\n\nAnyway, the [git documentation](https://git-scm.com/docs/git-config#Documentation/git-config.txt-coreexcludesFile) mentions the existence of a variable called `core.excludesFile`.\n\nIf you don't set it, and `$XDG_CONFIG_HOME` isn't overridden, you can add global ignores to `$HOME/.config/git/ignore`.\n\nLet's see this in action. First we'll make a brand new Git repository and add a `.DS_Store` file.\n\n```bash\n> mkdir sports\n> cd sports\n> git init\nInitialized empty Git repository in /Users/marcus/Code/sports/.git/\n> touch .DS_Store\n> git status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\t.DS_Store\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n```\n\nAh yes, the perpetual hell but let's try out our new trick.\n\n```bash\n> echo \".DS_Store\" >> ~/.config/git/ignore\n> git status\nOn branch main\n\nNo commits yet\n\nnothing to commit (create/copy files and use \"git add\" to track)\n```\n\nMwah, beautiful.\n","slug":"git-globally-ignore-files","tags":["git"],"title":"How can I globally ignore files?"},{"content":"If you've ever seen those pesky default folders like `Public` and `Movies`, the good news is that you can get rid of them.\n\nYou can't, or more specifically, you shouldn't fully delete them as some applications may assume their existence but you can get close enough.\n\nLet's say we want to hide `Public`, you can hide it from Finder like so:\n\n```shell\nchflags hidden ~/Public\n```\n\nThe next time you navigate to your Home directory using Finder, you'll see that they've magically disappeared\n\nIf you want to hide multiple at once, you can provide a comma delimited list:\n\n```shell\nchflags hidden ~/{Downloads,Public}\n```\n\nIf, for whatever reason, you wanted to block anyone or anything from accessing those folders as well, you could use `chmod` to do that:\n\n```shell\nchmod 000 ~/{Downloads,Public}\n```\n\nPersonally, I don't bother with this step but you might have a use for it.\n\nThe one issue with the above is that you'll see those files appear in your Terminal and I don't know about you but that basically makes this whole exercise pointless.\n\nThere are ways to do it but I haven't looked into them myself.\n","slug":"macos-hide-home-folders","tags":["housekeeping","macos"],"title":"How can I hide folders in my Home directory?"},{"content":"Using `pg_restore`, it's almost the same process as `pg_dump` but in reverse\n\n```bash\npg_restore --dbname={{DBNAME}} --host={{HOST}} --port={{PORT}} --username={{USERNAME}} --password --jobs 2 {{NAME}}.dump\n```\n","slug":"postgres-import-db","tags":["databases","postgres"],"title":"How can I import a dumped database into Postgres?"},{"content":"Until recently, I never had to go near SAML with a 10 foot pole but I was recently helping out a coworker with adding SAML authentication to an Elasticsearch cluster.\n\nI had never seen one before but a SAML request looks a little like this:\n\n```text\nhttps://idp.example.org/SAML2/SSO/Redirect?SAMLRequest=fZFfa8IwFMXfBb9DyXvaJtZ1BqsURRC2Mabbw95ivc5Am3TJrXPffmmLY3%2FA15Pzuyf33On8XJXBCaxTRmeEhTEJQBdmr%2FRbRp63K3pL5rPhYOpkVdYib%2FCon%2BC9AYfDQRB4WDvRvWWksVoY6ZQTWlbgBBZik9%2FfCR7GorYGTWFK8pu6DknnwKL%2FWEetlxmR8sBHbHJDWZqOKGdsRJM0kfQAjCUJ43KX8s78ctnIz%2Blp5xpYa4dSo1fjOKGM03i8jSeCMzGevHa2%2FBK5MNo1FdgN2JMqPLmHc0b6WTmiVbsGoTf5qv66Zq2t60x0wXZ2RKydiCJXh3CWVV1CWJgqanfl0%2Bin8xutxYOvZL18NKUqPlvZR5el%2BVhYkAgZQdsA6fWVsZXE63W2itrTQ2cVaKV2CjSSqL1v9P%2FAXv4C\n```\n\nI took [this example](https://en.wikipedia.org/wiki/SAML_2.0) from Wikipedia and it's a pretty good illustration of where the juicy part of the request probably is.\n\nA basic way to inspect this request in Python would look like the following. I don't claim that this will work on all requests. For that, try something like [python3-saml](https://github.com/onelogin/python3-saml).\n\n```python\nfrom base64 import b64decode\nfrom urllib.parse import unquote\nimport zlib\n\nurl = \"fZFfa8IwFMXfBb9DyXvaJtZ1BqsURRC2Mabbw95ivc5Am3TJrXPffmmLY3%2FA15Pzuyf33On8XJXBCaxTRmeEhTEJQBdmr%2FRbRp63K3pL5rPhYOpkVdYib%2FCon%2BC9AYfDQRB4WDvRvWWksVoY6ZQTWlbgBBZik9%2FfCR7GorYGTWFK8pu6DknnwKL%2FWEetlxmR8sBHbHJDWZqOKGdsRJM0kfQAjCUJ43KX8s78ctnIz%2Blp5xpYa4dSo1fjOKGM03i8jSeCMzGevHa2%2FBK5MNo1FdgN2JMqPLmHc0b6WTmiVbsGoTf5qv66Zq2t60x0wXZ2RKydiCJXh3CWVV1CWJgqanfl0%2Bin8xutxYOvZL18NKUqPlvZR5el%2BVhYkAgZQdsA6fWVsZXE63W2itrTQ2cVaKV2CjSSqL1v9P%2FAXv4C\"\nurldecoded_url = unquote(url)\nb64decoded_url = b64decode(url)\nrequest = zlib.decompress(b64decoded_url, -15).decode()\nprint(request) // '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\r\\n<samlp:AuthnRequest\\r\\n  xmlns:samlp=\"urn:oasis:names:tc:SAML:2.0:protocol\"\\r\\n  xmlns:saml=\"urn:oasis:names:tc:SAML:2.0:assertion\"\\r\\n  ID=\"aaf23196-1773-2113-474a-fe114412ab72\"\\r\\n  Version=\"2.0\"\\r\\n  IssueInstant=\"2004-12-05T09:21:59Z\"\\r\\n  AssertionConsumerServiceIndex=\"0\"\\r\\n  AttributeConsumingServiceIndex=\"0\">\\r\\n  <saml:Issuer>https://sp.example.com/SAML2</saml:Issuer>\\r\\n  <samlp:NameIDPolicy\\r\\n    AllowCreate=\"true\"\\r\\n    Format=\"urn:oasis:names:tc:SAML:2.0:nameid-format:transient\"/>\\r\\n</samlp:AuthnRequest>\\r\\n'\n```\n\nIf you're feeling a bit lazy, like I often am, you can use any of the online decoders, such as [this one by PingID](https://developer.pingidentity.com/en/tools/saml-decoder.html).\n\nIf you're dealing with sensitive credentials however, it's best to decode it locally rather than trusting a third party.\n\n\n","slug":"saml-inspect-request","tags":["authentication","saml"],"title":"How can I inspect a SAML request?"},{"content":"While you could provide a button, some parts of a site can look quite nice if they automatically transition between light and dark mode.\n\nYou can listen for these changes like so:\n\n```javascript\nwindow.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', e => {\n  const updatedScheme = e.matches ? \"dark\" : \"light\"\n  if (updatedScheme === \"dark\") {\n    // change something to dark mode\n  } else {\n    // change something to light mode\n  }\n})\n```","slug":"js-colour-scheme-listener","tags":["darkmode","javascript"],"title":"How can I listen for user changes to their colour scheme (ie dark mode)?"},{"content":"DNS! It's always the answer for your woes :)\n\nWhile there are a myriad of HTTP servers for seeing your external IP address, you can also use one of the various DNS based services on offer.\n\nThese will give you an IPv4 flag. The `-4` flag isn't necessarily required but without explicitly providing it, you'll be gambling on the return type.\n\n```\n> dig @resolver3.opendns.com myip.opendns.com +short -4\n> dig @resolver4.opendns.com myip.opendns.com +short -4\n> dig @ns1-1.akamaitech.net ANY whoami.akamai.net +short -4\n> dig @ns1.google.com TXT o-o.myaddr.l.google.com +short -4\n```\n\nand likewise, for IPv6\n\n```\n> dig @resolver1.ipv6-sandbox.opendns.com AAAA myip.opendns.com +short -6\n> dig @ns1.google.com TXT o-o.myaddr.l.google.com +short -6\n```\n\nYou can read more, and see some other providers I left out, in this [detailed StackOverflow thread](https://unix.stackexchange.com/questions/22615/how-can-i-get-my-external-ip-address-in-a-shell-script) but generally speaking, I've found OpenDNS's `resolver4` to be the fastest of the lot on offer.\n\nA very handy thing to have aliased and way quicker than clicking 5 times to navigate to a webpage.\n","slug":"dns-lookup-current-ip","tags":["dig","dns"],"title":"How can I look up my current external IP address?"},{"content":"For large downloads, such as macOS updates, it can be annoying that tools like Self Service don't surface download metrics\n\nThankfully, we can find the download on disk and watch as the file size increases\n\nIn the case of macOS, downloads live at `/Library/Application\\ Support/JAMF/Downloads`\n\nI'm no shell scripting master but the following is a quick hack to view the progress in real time\n\nThere are better tools like `watch` but eh, this works fine enough\n\nHere's the script I've been using but it requires `gnumfmt` which you can install with `brew install coreutils`\n\n```bash\n> while (true) do echo $(sudo ls -l /Library/Application\\ Support/JAMF/Downloads | grep macOS | awk '{ print $5 }' | gnumfmt --to iec --format \"Downloaded: %8.1f\"); sleep 15; done\nDownloaded: 6.9G\nDownloaded: 7.0G\nDownloaded: 7.0G\nDownloaded: 7.1G\nDownloaded: 7.1G\n```\n\nThat's not particulary readable so here's a bit of an explainer:\n\n```bash\nwhile (true)\ndo\n  echo $(\n    sudo ls -l /Library/Application\\ Support/JAMF/Downloads | # (1)\n    grep macOS | # (2)\n    awk '{ print $5 }' | # (3)\n    gnumfmt --to iec --format \"Downloaded: %8.1f\" # (4)\n  );\n  sleep 15; # (5)\ndone\n```\n\n1. Annoyingly, `JAMF/Downloads` is a restricted directory so we have to be a superuser in order to operate within that folder\n2. We're only concerned with one column in particular, in my case it's the macOS Big Sur DMG\n3. Let's fetch the current file size but just seeing `8466481152` is not particularly useful\n4. We can use `gnumfmt`, a GNU utils implementation of `numfmt` given the latter only exists on Linux systems. `gnumfmt` is available via Homebrew as mentioned above\n5. We just run this script continually until `Ctrl-C` is invoked. Over a average speed proxy, it takes about 45 seconds to download 100MB so there's no value personally in setting something like `sleep 5`\n\nEnjoy your window into frustration as you realise just how long waiting will take","slug":"macos-monitor-jamf-downloads","tags":["enterprise","jamf","macos","software"],"title":"How can I monitor JAMF downloads on macOS?"},{"content":"If you have a cronjob that you'd like to pause while doing some maintenance for example, you can use the `suspend` attribute.\n\n```bash\n> kubectl patch cronjobs does-something -p '{\"spec\": {\"suspend\": true }}'\ncronjob.batch/does-something patched\n```\n\nOnce you're done, you can just flip `true` to `false`","slug":"kubes-pause-recurring-cronjob","tags":["cronjob","kubernetes"],"title":"How can I pause a recurring Kube cronjob?"},{"content":"## How can I perform a regex search?\n\nYou can check if a character contains a string by using the cmatch operator like so:\n\n```powershell\n$word = \"Hello\"\n$word -cmatch \"[A-Z]\"\n// True\n```","slug":"powershell-regex","tags":["powershell"],"title":"How can I perform a regex search in Powershell?"},{"content":"Often times, it can be useful to check the value of a Kubernetes secret, to check that it lines up with what an application is receiving. An example might be a randomly generated secret that is shared between multiple Kubernetes resources.\n\nLet's have a look at a mock secret:\n\n```bash\n> kubectl describe secret dummy-secret\nName:         dummy-secret\nNamespace:    sports\nLabels:       app.kubernetes.io/managed-by=Helm\nAnnotations:  meta.helm.sh/release-name: sports\n              meta.helm.sh/release-namespace: sports\n\nType:  Opaque\n\nData\n====\nMY_FAVOURITE_FRUIT:  12 bytes\n```\n\nSo here we have a secret called `dummy-secret` and one of the values within it has the name `MY_FAVOURITE_FRUIT`.\n\nWe can fetch it like so:\n\n```bash\n> kubectl get secret dummy-secret -o jsonpath=\"{.data.MY_FAVOURITE_FRUIT}\" | base64 --decode\nstrawberries\n```\n","slug":"kubes-read-secret","tags":["credentials","kubernetes","security"],"title":"How can I read a Kubernetes secret?"},{"content":"I [recently came across an unsecured Selenium instance](https://twitter.com/sentreh/status/1435772900917735425) but I wanted to confirm my findings by making a basic request.\n\nWhile I opted to use the [Python bindings](https://pypi.org/project/selenium/) for [Selenium](https://www.selenium.dev/), there wasn't a quick start guide on how to remotely connect to an instance.\n\nHere's how you can quickly connect to a Selenium instance and do a basic request using Python:\n\n```python\n>>> from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n>>> from selenium import webdriver\n>>> hub_url = \"http://example.com:4444/wd/hub\"\n>>> driver = webdriver.Remote(command_executor=hub_url, desired_capabilities=DesiredCapabilities.CHROME)\n>>> driver.get(\"https://news.ycombinator.com\")\n>>> driver.find_element_by_tag_name(\"img\").get_attribute(\"src\")\n'https://news.ycombinator.com/y18.svg'\n```\n","slug":"selenium-remote-connection","tags":["python","selenium"],"title":"How can I remotely connect to a Selenium cluster"},{"content":"This one had my scratching my head a bit as I wasn't quite sure if Kubernetes was the right place to do this.\n\nDepending on your use case, it might make sense to terminate traffic before it reaches your cluster but that may have the effect of filtering traffic to other applications if not done properly.\n\nIn this instance, the Kubernetes cluster in question makes use of the [NGINX Ingress Controller](https://www.nginx.com/products/nginx-ingress-controller/) and as such, honours a whole bunch of flags.\n\nBefore we get into the details, let's set up a small example.\n\nWe'll pretend our desktop has an IP address is `192.0.2.3` exactly. We want to allow only a network range of 1 single address so that say; our mobile device with the address `192.0.2.2` can't connect but our desktop can.\n\nIn CIDR notation, this would be represented as `192.0.2.3/32`, with the `32` effectively meaning \"Just this one address\" instead of any other devices on the `192.0.2` range, or broader.\n\nWith our address block defined, let's look at an ingress:\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-cool-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/whitelist-source-range: \"192.0.2.3/24\"\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n        - path: /\n          backend:\n            service:\n              name: example-docs\n              port:\n                name: http-example-docs\n```\n\nOk, we've allowed our desktop to connect but let's try connecting to this ingress from a device we know isn't allowed, such as our laptop on `192.0.2.6`:\n\n```bash\n> curl https://example.com/\n<html>\n<head><title>403 Forbidden</title></head>\n<body>\n<center><h1>403 Forbidden</h1></center>\n<hr><center>nginx</center>\n</body>\n</html>\n```\n\nAlright, and now from our desktop at `192.0.2.3/24`, which we allowed explicitly:\n\n```bash\n> curl example.com\n<!doctype html>\n<html>\n<head>\n    <title>Example Domain</title>\n[...]\n```\n\nSuccess! We've managed to use nothing but an ingress to block specific traffic but you might wonder, why would I ever use this?\n\nOne use case may be exposing applications that require the use of a public endpoint, such as [Microsoft Teams](https://www.microsoft.com/en-ww/microsoft-teams/group-chat-software) or [Slack](https://slack.com).\n\nOften, you can't make use of OAuth but you want to protect against random internet traffic so you can explicitly allow known IP ranges.\n\nWith [Azure](https://azure.microsoft.com) for example, they publish a [full list of their active IP ranges](https://www.microsoft.com/en-us/download/details.aspx?id=56519) so if you can't simply make use of a [VNet](https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-overview), this may be the next best thing.","slug":"kubes-ingress-ip-range","tags":["allowlist","kubernetes"],"title":"How can I restrict which traffic is allowed to pass through a Kube ingress?"},{"content":"This issue is particularly annoying and I only just discovered it today for the first time.\n\nHere's an example of what it looks like\n\n![A macOS prompt stating that an application called matterhorn cannot be opened because the developer cannot be verified. The user is given the option to either move the application to the recycle bin or to cancel the interaction.](https://cdn.utf9k.net/questions/macos-port-5000-monterey/gatekeeper.png)\n\nIn order to install the application so that it bypasses Gatekeeper, you can rerun `brew cask install` like so:\n\n```shell\n> brew cask install --no-quarantine blah\n> brew reinstall --no-quarantine blah\n```\n\nIf you'd like to keep this flag enabled all the time, and honestly you might as well, you can also do the following:\n\n```shell\n> export HOMEBREW_CASK_OPTS=\"--no-quarantine\"\n> brew cask install blah\n```","slug":"macos-homebrew-app-blocked","tags":["gatekeeper","homebrew","macos"],"title":"How can I run a Homebrew application being blocked by Gatekeeper?"},{"content":"For those of us who are subject to using corporate VPNs, all sorts of wackiness can occur such as `127.0.0.1` being routed first to another country before trying to resolve locally.\n\nYou can see both IPv4 and IPv6 routing entries by running `netstat -rn`. Personally, I like to just show IPv4 addresses.\n\nHere's an example of my route table with WiFi (and ethernet) interfaces disabled:\n\n```shell\n> netstat -nr -f inet\nRouting tables\n\nInternet:\nDestination        Gateway            Flags        Netif Expire\n127                127.0.0.1          UCS            lo0\n127.0.0.1          127.0.0.1          UH             lo0\n111.0.0            link#1             UmCS           lo0\n```\n\nI've changed the last entry since I don't actually know if it's an internet work address.","slug":"macos-view-route-table","tags":["macos","networking","vpn"],"title":"How can I see my route table?"},{"content":"Recently I had noticed that some shell commands on my laptop were executing surprisingly slow.\n\nLike most things in the tech world, it was due to a piece of [jamf](https://www.jamf.com) software locking up anything that was being read.\n\nI managed to validate this assumption using the command `fs_usage` which requires sudo. Here's an example of it in action.\n\n```shell\n> sudo fs_usage | grep zshrc\nPassword:\n16:19:22  open              /Users/marcus/dotfiles/zsh/zshrc.md                                              0.000021   lugh\n16:19:22  open              /Users/marcus/dotfiles/zsh/.zshrc                                                0.000137   lugh\n16:19:22    WrData[A]       /Users/marcus/dotfiles/zsh/.zshrc                                                0.000324 W lugh\n16:19:22  lstat64           /System/Volumes/Data/Users/marcus/dotfiles/zsh/.zshrc                            0.000015   fseventsd\n16:19:22  lstat64           dotfiles/zsh/.zshrc                                                              0.000005   perl5.28\n16:19:22  lstat64           .zshrc                                                                           0.000007   perl5.28\n16:19:22  lstat64           .zshrc                                                                           0.000004   perl5.28\n16:19:22  readlink          .zshrc                                                                           0.000004   perl5.28\n16:19:22  stat64            dotfiles/zsh/.zshrc/.stow                                                        0.000002   perl5.28\n16:19:22  stat64            dotfiles/zsh/.zshrc/.nonstow                                                     0.000001   perl5.28\n16:19:22  stat64            dotfiles/zsh/.zshrc                                                              0.000004   perl5.28\n16:19:22  fsgetpath         /Users/marcus/dotfiles/zsh/.zshrc                                                0.000005   Finder\n16:19:22  getattrlist       /Users/marcus/dotfiles/zsh/.zshrc                                                0.000014   Finder\n16:19:22  fsgetpath         /Users/marcus/dotfiles/zsh/.zshrc                                                0.000005   Finder\n16:19:22  fsgetpath         /Users/marcus/dotfiles/zsh/zshrc.md                                              0.000005   Finder\n16:19:22  getattrlist       /Users/marcus/dotfiles/zsh/zshrc.md                                              0.000012   Finder\n16:19:22  fsgetpath         /Users/marcus/.zshrc                                                             0.000005   Finder\n16:19:22  getattrlist       /Users/marcus/.zshrc                                                             0.000015   Finder\n16:19:22  fsgetpath         /Users/marcus/zshrc.md                                                           0.000005   Finder\n16:19:22  getattrlist       /Users/marcus/zshrc.md                                                           0.000014   Finder\n16:19:22  fsgetpath         /Users/marcus/zshrc.md                                                           0.000003   Finder\n16:19:22  getxattr          dotfiles/zsh/zshrc.md                                                            0.000014   Finder\n16:19:22  fsgetpath         /Users/marcus/zshrc.md                                                           0.000004   Finder\n16:19:22  fsgetpath         /Users/marcus/zshrc.md                                                           0.000003   Finder\n16:19:23  lstat64           /System/Volumes/Data/Users/marcus/dotfiles/zsh/.zshrc                            0.000005   fseventsd\n```\n\nNow this output doesn't actually come from my work computer so you won't see the mentioned JamfAgent but we can walk through this anyway.\n\nFirst is [lugh](https://github.com/marcus-crane/lugh), a custom and possibly temporary literate markdown tool I use on my dotfiles. Next is `perl`, in the form of [GNU Stow](https://www.gnu.org/software/stow/) followed by macOS Finder doing some things. This gives a really nice breakdown of what is going on.\n\nYou can even use it to better understand applications, like if you run `git status` and see all the files that were touched within the `.git` folder.\n\nI actually spotted that Yet Another Daemon was touching some of my `.git` files on my work laptop too. Shoo!","slug":"macos-see-file-usage","tags":["enterprise","jamf","macos","performance","terminal"],"title":"How can I see what applications are making my shell commands slow?"},{"content":"By default, kubectl will search the `default` namespace for any newly added clusters to your context, which can be quite annoying.\n\nYou can of course tack on `-n <namespace>` manually or make your own little wrapper around kubectl as I have.\n\nA simpler version though is to just do the following:\n\n```bash\nkubectl config set-context --current --namespace=baseball\nContext \"sports\" modified\n```\n\nWhere `baseball` is the name of your namespace of course.\n\nGoing forward, any commands will default to use the `baseball` namespace but you can override them as always with `-n`.","slug":"kubes-default-namespace","tags":["defaults","kubectl","kubernetes"],"title":"How can I set a default kubectl namespace for a given cluster?"},{"content":"Often times, you might want to test connectivity to a container but without doing so from within the container itself. You could just into a neighbouring pod but it may not have networking tools (ie tools) or even potentially network connectively if there's a [network policy](https://kubernetes.io/docs/concepts/services-networking/network-policies/) in the mix.\n\nA quick way to deploy a curl container has been shared before [in the Kubernetes docs](https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#securing-the-service) and it looks like this:\n\n```bash\n> kubectl run curl --image=radial/busyboxplus:curl -i --tty\nUnable to use a TTY - container curl did not allocate one\nIf you don't see a command prompt, try pressing enter.\n```\n\nI think the output looks something like that but this is a bit more involved as my work makes use of [policies](https://docs.microsoft.com/en-us/azure/governance/policy/concepts/policy-for-kubernetes) in our cluster.\n\nNow normally I just keep a file called `curl-debug.yml` sitting around my hard drive and deploy it using `kubectl apply -f curl-debug.yml`\n but you can also deploy it inline using a hideously log container override.\n\nYou may need more (or less) override fields depending on eg; if your network policy only allows pods with certain annotations or metadata to connect to what you're testing.\n\nAn unprivileged curl pod would look something like this. Note that I've removed `-i --rm --tty` as it always seems buggy to me and I much prefer to just manually run `kubectl exec -it curl -- sh` than have my terminal hanging.\n\n```bash\n> kubectl run curl --image=radial/busyboxplus:curl --overrides='{ \"spec\": { \"securityContext\": { \"runAsUser\": 1000, \"runAsGroup\": 1000, \"seccompProfile\": { \"type\": \"RuntimeDefault\" }}, \"containers\": [{ \"name\": \"curl\", \"image\": \"radial/busyboxplus:curl\", \"command\": [ \"/bin/sh\", \"-c\", \"--\" ], \"args\": [ \"while true; do sleep 30; done; \" ], \"securityContext\": { \"runAsNonRoot\": true, \"allowPrivilegeEscalation\": false }}]}}\npod/curl created\n```\n\nand for those who don't love huge eyesores, here's the contents of the pod spec I alluded to earlier:\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: \"curl\"\n  labels:\n    app: \"my-cool-app\"\n    service: \"some-other-identifier\"\nspec:\n  securityContext:\n    runAsUser: 1000\n    runAsGroup: 1000\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: \"curl\"\n    image: \"radial/busyboxplus:curl\"\n    command: [ \"/bin/sh\", \"-c\", \"--\" ]\n    args: [ \"while true; do sleep 30; done;\" ]\n    securityContext:\n      runAsNonRoot: true\n      allowPrivilegeEscalation: false\n```\n\nAh right, the actual point of the question. Once you have curl running, and you're inside the container, you can then use `curl` to test out the connectivity of things.\n\nFor example, earlier today I was moving a container to a new cluster and it was using the URL that the ingress was listening to. Let's use `https://sports.example.com` in this case and say that the service was called `sports`.\n\nThe ingress URL changed from being internally accessible to publically accessable, although behind an OAuth2 proxy of course.\n\nI noticed this change by doing the following:\n\n```bash\n> curl --head --location http://sports\nHTTP/1.1 200 OK\nServer: nginx\n[...]\n```\n\nOk, it resolves the internal service perfectly fine. How about the public one?\n\n```bash\n> curl --head --location https://sports.example.com\nHTTP/1.1 302 Moved Temporarily\nLocation: https://example.com/_oauth2/start?rd=https://sports.example.com\n[...]\n\nHTTP/1.1 302 Found\nLocation: https://login.microsoftonline.com/common/oauth2/authorize?a_very_long_string\n[...]\n\nHTTP/1.1 200 OK\nContent-Length: 186288\n[...]\n```\n\nNow, I don't even have to look at the payload to infer that we probably just hit an OAuth2 login page and that's exactly what was happening.\n\nIn the previous cluster, we were using internal links to the external OAuth proxy is never involved. Admittedly, this was rationalised as \"DNS just magically knows to resolve the request to the service right next door\" and perhaps this is true but maybe not!\n\nAnyway, a third case that you might run into is the following:\n\n```bash\n> curl --head --location http://something\n# the command just sits with no output forever!\n```\n\nIf you check my `curl-debug.yaml`, I have specific labels that the network policy looks for. Because this curl pod is missing them, it can't make any requests.\n\nThis could be anything from protocol (TCP/UDP), port number, whitelisted namespaces, whitelisted resources and so on. If you have this problem, either check your various log messages for reference to a required policy or check for an existing one that needs to be updated.\n\nDoing a search for \"kind: NetworkPolicy\" should help narrow down which files are relevant and/or if they even exist in the first place.\n\nHappy debugging!","slug":"kubes-namespace-connectivity","tags":["curl","debugging","kubernetes","networking"],"title":"How can I test connectivity within my Kube namespace?"},{"content":"There is a CLI tool called [xcall](https://github.com/martinfinke/xcall) which seems to be the only way I've seen to actually interact with `x-callback-url` outside of other applications.\n\nIt's a bit wonky in that you have to drag `xcall.app` to your `Applications` folder and then either add that to your path or reference the cli tool inside directly.\n\nHere's an example of it in use:\n\n```bash\n> /Applications/xcall.app/Contents/MacOS/xcall -url \"things:///version\" -activateApp NO\n{\n  \"x-things-client-version\" : \"31310506\",\n  \"x-things-scheme-version\" : \"2\"\n}\n```\n\nAnnoyingly, this will activate the application in question, if it isn't already open, but that is the nature of `x-callback-url` after all.\n\nIt will take the foreground view upon opening but further invocations won't trigger it, assuming you use `-activateApp NO`. If you want it to appear, such as when triggering a search, you can use `-activateApp YES` instead.\n","slug":"macos-invoke-x-callback-url","tags":["macos","x-callback-url"],"title":"How can I try out x-callback-url commands on macOS?"},{"content":"From time to time, I have troubles with Firefox since it seems to clash with a corporate proxy we use.\n\nUsing the built-in certificate store rather than Firefox's own managed store seemed to \"fix\" this issue.\n\nTo do this, you'll want to navigate to `about:config` and then toggle `security.enterprise_roots.enabled` to `true`.\n","slug":"firefox-local-cert-store","tags":["browsers","enterprise","firefox","software"],"title":"How can I use my local certificate store with Firefox?"},{"content":"Let's assume you have multiple networks set up under `System Preferences > Networks`.\n\nYou might have \"Work\" which has a bunch of proxy configuration specified and \"Home\" which just disabled proxy configuration.\n\nIf you left the former \"Work\" network selected, then went to a place that can't access the proxy server, you wouldn't be able to access the internet and vice versa.\n\nTo make automating this a little bit easier, there's a command line tool called `scselect`\n\nHere's an example of what it looks like in action:\n\n```bash\n> scselect\nDefined sets include: (* == current set)\n * <guid> (Work)\n   <guid> (Home)\n```\n\nIn this example, we can see the `Work` network is selected.\n\nNow we wanted to change to the Home network, you could do so manually in `System Preferences` or you can run `scselect` with the name of the network you want to change to like so:\n\n```bash\n> scselect Home\nCurrentSet updated to <guid> (Home)\n> scselect\nDefined sets include: (* == current set)\n   <guid> (Work)\n * <guid> (Home)\n```\n\nAs you can see, the `Home` network is now selected.\n\nI only recently discovered this tool so I haven't automated it yet but it's probably feasible to have a file with your working hours and then if it's within those hours, toggle on the `Work` network (and all of the proxy configuration that comes with it)\n\nThe reason you might want to use a schedule and not eg; WiFi name is that you might be working from home over a VPN for example.","slug":"macos-configured-networks","tags":["macos","networking"],"title":"How can I view configured networks in my macOS terminal?"},{"content":"The iex interpreter includes a function called h which can be used to show documentation for a module\n\n```elixir\nh String\n# h/1\n```\n","slug":"elixir-help-docs","tags":["elixir"],"title":"How can I view help documentation for an Elixir module?"},{"content":"Let's say we have the following module\n\n```elixir\ndefmodule Reminder do\n  def alarm(time, day) do\n  end\nend\n```\n\nWe can check what methods are on it by providing a `:functions` atom\n\n```elixir\nReminder.__info__(:functions)\n# [alarm: 2]\n```\n\nAs we can see, this Reminder module has an alarm method, with an arity of 2.\n","slug":"elixir-object-methods","tags":["elixir"],"title":"How can I view methods associated with an Elixir object?"},{"content":"Let's say that you have a variable that contains a string:\n\n```powershell\n$a = \"abc\"\n```\n\nThat's neat but what if I want to view the possible methods that are available on the string object? You can use the Get-Member cmdlet. You can also use the shorthand version gm.\n\n```powershell\n$a = \"abc\"\n$a | gm\n// Name | MemberType | Definition\n// Clone | Method | System.Object Clone() [...]\n// ...\n// Length | Property | int Length {get;}\n$a.Length\n// 3\n```\n\nYou can also view the static methods associated with an object too:\n\n```powershell\n\"abc\" | gm - Static\n// Compare | Method | static int Compare(string strA, string strB)...\n```","slug":"powershell-object-methods","tags":["powershell"],"title":"How can I view the methods associated with an object?"},{"content":"According to the [Storage](https://prometheus.io/docs/prometheus/latest/storage/#operational-aspects) part of the Prometheus documentation, a single sample is somewhere between 1 - 2 bytes.\n\nYou can roughly calculate how much storage you'll need with the following formulae:\n\n```text\ndisk_space = retention_time_in_seconds * samples_ingested_per_second * 2 bytes (take the upper to be safe)\n```\n\nBy that logic, if we were ingesting 4000 samples per second and we were retaining them for 15 days (the default), it would look something like this:\n\n```text\ndisk_space = 1296000 * 4000 * 2\ndisk_space // 10368000000 bytes\ndisk_space in gigabytes // 10.37 gigabytes\n```\n\nGiven this, you can see the levers you have are decreasing the amount of sampling going on, reducing the amount of time samples are retained for or simply buying more disk space as you go on.\n\nRemember as well that we took the high end of the estimation and it could be as low as 5.185 if we're extremely lucky on compression and/or presumably we have next to no labels on each sample.\n\nYou would also need to factor in many other things such as the [write-ahead log](https://www.robustperception.io/how-much-space-does-the-wal-take-up) but I don't pretend to know what any of these things are.\n\nI just use Prometheus! I don't actually maintain a cluster or anything like that.","slug":"prometheus-sample-size","tags":["monitoring","prometheus","timeseries"],"title":"How large is a single Prometheus sample?"},{"content":"Back in the day, there was just one file: `HOSTS.TXT`.\n\nIt contained a name-to-address mapping for every entity within [ARPANET](https://en.wikipedia.org/wiki/ARPANET).\n\n`/etc/hosts` used to be compiled from `HOSTS.TXT`\n\nIt didn't scale for a number of reasons:\n\n- As soon as administrators pulled the latest version of HOSTS.TXT, it would already be out of date\n- There was no way to enforce constraints eg; no duplicates on hostnames\n- It took a lot of resources to serve it up to every administrator","slug":"dns-original-implementation","tags":["dns","historical"],"title":"How was DNS originally implemented?"},{"content":"An initial thought might be that it would help to capture all context about everything, all of the time but that would soon get very expensive to store.\n\nProfiling takes the approach of capturing as much context as possible for a certain period of time, generally for use in debugging.\n\nContinually gathering information, such as how long each function took to execute, in a production environment would very quickly impact end users so this is best suited for validating targeted assumptions of what might be going wrong.\n","slug":"monitoring-what-is-profiling","tags":["instrumentation","monitoring"],"title":"What is profiling?"},{"content":"The root node of DNS has a `null` label\n\nThe DNS tree is restricted to 127 levels of depth so you could `only.have.a.domain.name.one.hundred.and.twenty.seven.levels.deep.com`\n\n`.` is used to mark a domain as absolute eg; `utf9k.net.`\n\nBehind the scenes, a full domain name would be `www.google.com.<root/null>`\n\nSome websites, or perhaps more accurately the load balancers and proxies in front of them, don't acknowledge the existence of such a thing.\n\nOne high profile example is Amazon. If you visit [https://amazon.com.](https://amazon.com.), you'll see a blank page with the title `x`. Note the period on the end of the URL to see this issue in effect.","slug":"dns-trailing-period","tags":["dns","historical","networking"],"title":"What is the period you sometimes see at the end of a domain name?"},{"content":"In the same vein that it's not often feasible to capture all data, all of the time, tracing is concerned with sampling a subset of events such as every 50th incoming request.\n\nGenerally most tracing implementations will show you how much time is spent at each step of the way from establishing an SSL connection through to how long is spent talking with any given database.\n\nDistributed tracing is this same idea but... well, distributed.\n\nMore specifically, interactions are \"tagged\", whether it be an HTTP header or an attribute within an RPC call. While those interactions may pass the boundaries of any one service, they can be \"stitched\" back together by matching up the associated request IDs.\n\nThe idea here being that you can trace a request through a system oriented around microservices, as if it were just one regular application.\n\nGiven that only a subset of interactions (ie 1 in 100) are sampled, this solves the storage issues presented by full on profiling all of the time.","slug":"monitoring-tracing-overview","tags":["instrumentation","monitoring"],"title":"What is tracing?"},{"content":"I've been fiddling a bit with [Wails](https://github.com/wailsapp/wails) recently and I gave the unreleased v2 alpha a try.\n\nOut of the box, it binds to Port 5000 and I was surprised to receive a `403 Forbidden`.\n\nDefinitely not what I expected.\n\n![A Brave browser window showing 403 Forbidden when trying to view localhost port 5000](https://cdn.utf9k.net/questions/macos-port-5000-monterey/403-forbidden.png)\n\nWe can use the `lsof` utility to figure out what's holding on to Port 5000. You'll see in the screenshot below that I use a shell function called `whomport` but under the hood, it's running `lsof -nP i4TCP:5000 | grep LISTEN`. Let's see what the output looks like.\n\n![A screenshot showing two windows. One is a Terminal with the output of a command called whomport. It shows Control Center listening on Port 5000 with the Process ID 2273. Behind the Terminal is Activity Monitor. Control Center is highlighted and indeed has the same Process ID of 2273.](https://cdn.utf9k.net/questions/macos-port-5000-monterey/whomport.png)\n\nThis doesn't really help us much since Control Centre could be anything but a bit of searching brings up that this change was introduced in macOS Monterey.\n\nIn particular, there's a new setting under `System Preferences` -> `Sharing` called `Airplay Receiver`.\nLet's toggle it off.\n\n![A screenshot showing the Sharing pane of macOS System Preferences. Airplay Receiver has been unticked.](https://cdn.utf9k.net/questions/macos-port-5000-monterey/airplay-sharing.png)\n\nOnce this is done, you should find Port 5000 instantly freed up. It's weird that Apple would pick such a commonly used port, especially for developers!","slug":"macos-port-5000-monterey","tags":["airplay","macos","monterey","receiver"],"title":"What is using Port 5000 on macOS Monterey?"},{"content":"Services and libraries have different needs. Further, not all services are alike in the types of work they perform or what types of work are important to measure\n\n### Online-serving systems\n\nThese are services that have a person or client waiting for a response.\n\nAs such, the [RED method](https://www.weave.works/blog/the-red-method-key-metrics-for-microservices-architecture/) captures key metrics which are Requests, Errors and Duration.\n\nIt's worth noting that there may be a tendency to exclude failed requsts when capturing duration but this temptation should be avoided.\n\nIn the event that you only had successes, a long running request that ultimate failed after 15 seconds would be excluded for example, despite any reasonable initial assumption that errors may tend towards having a lower duration.\n\n### Offline-serving systems\n\nThese are services that operate continually in the background. Their workloads are generally in batches and may utilise multiple steps, buffered with a queuing system.\n\nThe [USE method](http://www.brendangregg.com/usemethod.html) captures key metrics which are Utilisation, Saturation and Errors.\n\n### Batch jobs\n\nSimilar to offline-serving systems, these may be kicked off upon request (ie sending an email in the background) or something akin to a cronjob.\n\nGiven that they aren't suitable for serving a persistent HTTP endpoint for scraping, it's best to push metrics to a monitoring solution such as Prometheus upon work being completed.\n","slug":"monitoring-what-to-instrument","tags":["instrumentation","monitoring"],"title":"What is worth instrumenting?"},{"content":"One of the primary considerations of the HTTP2 Working Group was definitely that encouraging HTTPS meant a more secure web.\n\nMore practically however, there had been previous experiments using WebSockets and SPDY which showed that regular HTTP requests were highly prone to failure due to things like proxies interrupting negotiation.\n\nOften times, an `Upgrade` header was supplied with the initial HTTP negotiation and then shortly both sides upgraded to HTTPS but if HTTPS was used from the outside, there would be a significantly easier time doing protocol negotiation.\n\nThere is an overhead to establishing a TLS connection of course but the price pays off in the form of HTTP2 multiplexing and so on.","slug":"http-non-encryption-benefits","tags":["historical","http","reliability"],"title":"What non-encryption benefits are provided by HTTPS?"},{"content":"Rob Pike explained his understanding in a now-dead Google+ post back in 2012. The use of `.` and `..` had appeared in early versions of the Unix file system, as a quick way to navigate around. They would appear when using `ls` to view the contents of a directory so a line was added that ignored anything where the first character was a period.\n\nThis, of course, meant that any files starting with a `.` were also hidden and so began years of bad practices. Rather than think \"Where should I store my configuration folder\", the easy option became storing a dotfile instead. It may be messy but if no one can see it, is it really so bad?\n\nRob also points out that configuration could just as easily be stored in `$HOME/cfg` or `$HOME/lib` as was the case in Plan 9. He doesn't dispute that dotfiles have their uses but emphasizes that the file itself serves the purpose. Prepending a dot does not a configuration file make.","slug":"linux-why-do-dotfiles-exist","tags":["historical","linux","macos"],"title":"Why are dot files a thing?"},{"content":"On April 20th 2020, oil futures fell to $-37.63 per barrel but how is that possible? That would suggest people are literally paying customers to take oil off their hands.\n\nIn a sense, that's exactly the case but perhaps not for quite the reasons you might expect.\n\n## What are oil futures?\n\n> with the pandemic bringing the economy to a standstill, there is so much unused oil sloshing around that American energy companies have run out of room to store it. And if theres no place to put the oil, no one wants a crude contract that is about to come due.\n\nIn reality, traders hold a contract that, generally after about 3 months, is translated into a physical delivery of oil.\n\nFor example, someone may pay $40 per barrel in January. Oil may be worth $60 in March so a trader might then sell the contract for a $20 profit, as I understand it anyway.\n\nFutures are designed for people who actually want to purchase oil, or any future-able item like wheat, corn and so on.\n\nThat doesn't stop a whole portion of Wall Street who speculate on these futures however.\n\nThere are some funny stories about junior traders who have forgotten to sell their contract and have been required to take delivery of hundreds of physical barrels of oil.\n\n## Receiving delivery\n\nThe city of [Cushing, Oklahoma](https://en.wikipedia.org/wiki/Cushing,_Oklahoma) is called the \"Pipeline Crossroads of the World\" and is where a great deal of oil is stored in the United States.\n\nWhen it comes to oil futures, Cushing is also the one and only [designated delivery point](https://en.wikipedia.org/wiki/Cushing,_Oklahoma#Oil_futures_designated_delivery_point_in_the_US).\n\nNormally, oil is stored there on behalf of those who lease between 50 - 80 million barrels worth of storage.\n\n## Why did oil futures turn negative?\n\nGiven Coronavirus meant that most of the world was at home, oil producers had little option but to store their oil.\n\nWhen it came time for those futures to convert into physical oil, there was no actual storage left for traders to purchase.\n\n> With nowhere to store their oil, and the foreboding promise of exorbitant storage fees at the delivery site, the holders of oil delivery contracts were forced to pay buyers with oil storage contracts to take the product off their hands, upending the market and sending the entire industry into unknown, negative territory.\n\nFaced with the horrifying idea of having to drive all the way to Cushing, Oklahoma to somehow receive thousands of barrels of oil, it became more appeals to just pay almost $40/barrel for someone else to take the future (and impending delivery) off of their hands\n\nStorage may have been possible but at a time where it was in high demand, the excesses would have been astronomical.\n\nNot to mention, there was already an overabundance of oil for the foreseeable future so it would take a long time to realise a profit, if at all.\n\n## Sources\n\n* [https://www.bloomberg.com/opinion/articles/2020-04-22/nobody-wants-much-oil-right-now](https://www.bloomberg.com/opinion/articles/2020-04-22/nobody-wants-much-oil-right-now)\n    \n* [https://www.bloomberg.com/opinion/articles/2020-04-28/oil-traders-not-sure-they-like-oil](https://www.bloomberg.com/opinion/articles/2020-04-28/oil-traders-not-sure-they-like-oil)\n    \n* [https://www.reuters.com/article/us-global-oil-usa-storage/no-vacancy-main-us-oil-storage-in-cushing-is-all-booked-idUSKCN22332W](https://www.reuters.com/article/us-global-oil-usa-storage/no-vacancy-main-us-oil-storage-in-cushing-is-all-booked-idUSKCN22332W)\n  \n* [https://www.cushingcitizen.com/news/oil-turns-red](https://www.cushingcitizen.com/news/oil-turns-red)\n    \n\n## Further reading\n\n* [https://www.npr.org/sections/money/2016/08/26/491342091/planet-money-buys-oil](https://www.npr.org/sections/money/2016/08/26/491342091/planet-money-buys-oil)\n","slug":"finance-oil-futures-negative","tags":["finance","futures"],"title":"Why did oil futures go negative in April 2020?"},{"content":"It was common to have images on a subdomain and the bulk of the site at the root of a domain such as `nytimes.com` and `img.nytimes.com`\n\nCaching is widely understood as the current value but it doesn't capture the historical context behind the introduction of this tactic.\n\nAnother aspect is that the size of headers bloated significantly, sometimes to where cookies associated with a request would be larger than a single TCP packet, which is about 1.5kb.\n\nIn order to reduce latency, it made sense to move resources that didn't require cookies to a separate domain, so that those requests didn't inherit excess headers. While not large on a single request, requests for multiple assets would balloon exponentially.\n\nThis practice was colloquially referred to as a \"cookie-less domain\".\n","slug":"http-domain-splits","tags":["cookies","headers","historical","http"],"title":"Why did sites split their assets across multiple domains back in the day?"},{"content":"The Playstation 1 uses CD-ROMs with the [XA extension](https://en.wikipedia.org/wiki/CD-ROM#CD-ROM_XA_extension).\n\nIf you open a PS1 ISO within a hex editor, you'll want to scroll down to `offset 37656`\n\nWithin a normal CD (or ISO), it will have a header offset size of `2048`.\n\nIt seems a little arbitrary but you can read the table of contents by multiplying the header offset by 16.\n\nFor a normal CD, this would be `2048 * 16 = 32768`\n\nIn the case of PS1 discs, the header offset size is `2352` for reasons I don't understand so they start at `2352 * 16 = 37632`\n\nLastly, and somewhat arbitrarily, you'll want to jump forward by an additional `24` bytes in order to come to the starting point of `37565 points`\n","slug":"ps1-disc-offset","tags":["hexedit","playstation","videogames"],"title":"Why do Playstation 1 discs start at offset 37656?"},{"content":"As an example of what I mean, `org-roam` had seemingly the same function names at one point, despite the only difference being some double dashes\n\n[Here is an example](https://github.com/org-roam/org-roam/blob/ba835ef6242caf23e60ab9de1aaf1f25d7e5841f/org-roam-capture.el#L236)\n\nAt first glance, the naming differences between `org-roam-capture--get-point` and `org-roam--capture-get-point` seems completely arbitrary\n\nSupposedly, [since there is no such thing as internal vs external functions](https://emacs.stackexchange.com/questions/42286/double-hyphen-in-elisp-function-names), it's a convention for declaring that a function should be considered private or internal only\n\nI still don't understand the above example since they both have double hyphens","slug":"emacs-function-double-dash","tags":["elisp","emacs"],"title":"Why do some Emacs functions have double dashes?"},{"content":"Lists that start with a `` ` `` end up having values interpolated.\n\nCompare the following two examples:\n\n```lisp\n'(,(concat \"Hello, \" \"World\"), \"Nice to meet you?\")\n; (,(concat \"Hello, \" \"World\")\n;   ,\"Nice to meet you?\")\n```\n\nAs you can see, we got the exact same list that we defined when starting with a `'`\n\nHow about using a `` ` ``?\n\n```lisp\n`(,(concat \"Hello, \" \"World\"), \"Nice to meet you?\")\n; (\"Hello, World\" \"Nice to meet you?\")\n```\n\nThe `concat` expression is evaluated and we get back two strings!","slug":"emacs-list-backtick","tags":["elisp","emacs"],"title":"Why do some Emacs lists start with a backtick instead of a comma?"},{"content":"I recently ran into this issue when switching my distro to [Manjaro](https://manjaro.org).\n\nI'd find that whenever a different audio source would start playing such as a voice call, notification or even a silent video on the web, my Spotify audio would drop to 0 instantly\n\nIn order to fix this, all I needed to do was unload the `module-role-cork` module presumably used by `pulseaudio`\n\nYou can toggle via your terminal to test that it works like so:\n\n```shell\n> pactl unload-module module-role-cork # disabled, try spotify and another audio source\n> pactl load-module module-role-cork   # enabled, spotify should be interrupted\n```\n\nWhile I'm not sure how long `unload-module` persists (I'm guessing until the next restart), you can achieve the same effect by commenting out the module in the configuration for `pulseaudio` like so:\n\n```shell\n> grep \"cork\" /etc/pulse/default.pa -B 3\n### Cork music/video streams when a phone stream is active\n# Disabling this allows audio streams to run over the top of each other\n# Before this, a newer stream (notification, video) would mute Spotify\n#load-module module-role-cork\n```\n\nOnce that's done, you should be good to go. It seems to work as expected for me anyway.","slug":"linux-audio-muting-suddenly","tags":["audio","bugs","linux","spotify"],"title":"Why do some of my applications suddenly get muted on Linux?"}]